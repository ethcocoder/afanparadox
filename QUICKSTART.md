# AfanParadox Voice Intelligence System

## üöÄ Quick Start Guide

### What We've Built So Far

‚úÖ Complete project structure  
‚úÖ ASR module (Wav2Vec2-based speech recognition)  
‚úÖ LLM module (Morphology-aware Ethiopian tokenizer)  
‚úÖ TTS module (framework ready)  
‚úÖ Voice Assistant integration pipeline  
‚úÖ Audio recording tool for data collection  
‚úÖ Demo system

### Installation

```bash
cd afanparadox

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### Running the Demo

```bash
# Test the voice assistant (simulated)
python scripts/demo_voice.py
```

### Collecting Voice Data

```bash
# Record Ethiopian speech for training
python scripts/record_audio.py
```

### Next Steps

1. **Collect Data**: Use `record_audio.py` to gather Ethiopian speech samples
2. **Train ASR**: Fine-tune Wav2Vec2 on collected speech data
3. **Train LLM**: Build Ethiopian language corpus and train transformer
4. **Train TTS**: Record professional voice and train synthesis model
5. **Integrate**: Combine all three models into voice assistant

## üèóÔ∏è Architecture

**Language**: Python 3.9+ (chosen for best ML ecosystem)

**Three-Model System**:
- **ASR** (Ears): Wav2Vec2-XLS-R ‚Üí Amharic/Oromo/Tigrinya speech recognition
- **LLM** (Brain): Morphology-aware transformer ‚Üí cultural reasoning
- **TTS** (Voice): FastSpeech2 + HiFiGAN ‚Üí natural speech synthesis

**Integration**: Real-time voice pipeline with <2s latency

## üìÅ Current Structure

```
afanparadox/
‚îú‚îÄ‚îÄ afanparadox/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ asr/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py          ‚úÖ Wav2Vec2 ASR
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py      ‚úÖ Ethiopian tokenizer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ tts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ       ‚îú‚îÄ‚îÄ voice_assistant.py ‚úÖ End-to-end pipeline
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ demo_voice.py         ‚úÖ Demo
‚îÇ   ‚îî‚îÄ‚îÄ record_audio.py       ‚úÖ Data collection
‚îú‚îÄ‚îÄ config.yaml                ‚úÖ Configuration
‚îú‚îÄ‚îÄ requirements.txt           ‚úÖ Dependencies
‚îú‚îÄ‚îÄ setup.py                   ‚úÖ Package setup
‚îî‚îÄ‚îÄ README.md
```

## üéØ Current Status

- ‚úÖ **Project Setup**: Complete
- ‚úÖ **Core Architecture**: Built
- üîÑ **Data Collection**: Tools ready, need data
- ‚è≥ **Model Training**: Awaiting data
- ‚è≥ **Integration**: Framework ready
- ‚è≥ **Deployment**: Planned

## üí° What's Working

- Project structure is production-ready
- ASR model can load Wav2Vec2 (needs fine-tuning on Ethiopian data)
- Ethiopian tokenizer has morphology awareness (needs training)
- Voice assistant pipeline is ready to integrate models
- Recording tool can collect training data

## üî• Next Immediate Actions

1. **Install dependencies**: `pip install -r requirements.txt`
2. **Test demo**: `python scripts/demo_voice.py`
3. **Start collecting data**: Use recording tool
4. **Fine-tune ASR**: Once we have 10+ hours of speech
5. **Train tokenizer**: On Ethiopian text corpus

Ready to start training models as soon as data is collected! üöÄ
